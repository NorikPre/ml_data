{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: mlflow in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: pandas in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: category_encoders in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: pytz<2023 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (2022.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (2.28.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (0.4.3)\n",
      "Requirement already satisfied: alembic<2 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (1.10.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: pyarrow<12,>=4.0.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (8.0.0)\n",
      "Requirement already satisfied: Flask<3 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (1.4.46)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (3.20.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (5.2.0)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (3.1.31)\n",
      "Requirement already satisfied: cloudpickle<3 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: entrypoints<1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (3.5.3)\n",
      "Requirement already satisfied: packaging<24 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (22.0)\n",
      "Requirement already satisfied: shap<1,>=0.40 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (0.41.0)\n",
      "Requirement already satisfied: querystring-parser<2 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: gunicorn<21 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (0.17.4)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (6.0.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: Mako in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from alembic<2->mlflow) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from alembic<2->mlflow) (4.4.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from docker<7,>=4.0.0->mlflow) (1.26.14)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from Flask<3->mlflow) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from gunicorn<21->mlflow) (65.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.39.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from shap<1,>=0.40->mlflow) (4.65.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from shap<1,>=0.40->mlflow) (0.0.7)\n",
      "Requirement already satisfied: numba in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from shap<1,>=0.40->mlflow) (0.56.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (3.0.5)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/norik/opt/anaconda3/envs/DHBW/lib/python3.10/site-packages (from numba->shap<1,>=0.40->mlflow) (0.39.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn mlflow pandas category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from typing import Dict, List, Tuple, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \"autos.csv\" file into \"data\" DataFrame\n",
    "data = pd.read_csv(\"autos.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in data: 0\n",
      "YEAR                  int64\n",
      "MAKE                 object\n",
      "MODEL                object\n",
      "VEHICLE CLASS        object\n",
      "ENGINE SIZE         float64\n",
      "CYLINDERS             int64\n",
      "TRANSMISSION         object\n",
      "FUEL                 object\n",
      "FUEL CONSUMPTION    float64\n",
      "HWY (L/100 km)      float64\n",
      "COMB (L/100 km)     float64\n",
      "COMB (mpg)            int64\n",
      "EMISSIONS             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from the \"data\" DataFrame\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Print the number of missing values\n",
    "print(\"NaN values in data: \" + str(data.isnull().sum().sum()))\n",
    "\n",
    "# Print the data type of each column\n",
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encode the follwing columns\n",
    "columns_to_encode = [\"MAKE\", \"VEHICLE CLASS\", \"TRANSMISSION\"]\n",
    "encoder = ce.TargetEncoder(cols=columns_to_encode)\n",
    "encoder.fit(data[columns_to_encode], data[\"COMB (L/100 km)\"])\n",
    "encoded_data = encoder.transform(data[columns_to_encode])\n",
    "encoded_data.columns = [f\"{col}_enc\" for col in columns_to_encode]\n",
    "data = pd.concat([encoded_data, data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MAKE_enc  VEHICLE CLASS_enc  TRANSMISSION_enc  YEAR  ENGINE SIZE  \\\n",
      "0  9.398477           9.180804         12.304974  2000          1.6   \n",
      "1  9.398477           9.180804          9.381036  2000          1.6   \n",
      "2  9.398477           9.791304         10.849480  2000          3.2   \n",
      "3  9.398477           9.791304         12.304974  2000          3.5   \n",
      "4  9.398477           9.908146         12.304974  2000          1.8   \n",
      "\n",
      "   CYLINDERS TRANSMISSION  FUEL  COMB (L/100 km)  \n",
      "0          4           A4     2              8.1  \n",
      "1          4           M5     2              7.6  \n",
      "2          6          AS5     3             10.0  \n",
      "3          6           A4     3             11.5  \n",
      "4          4           A4     2              8.6  \n"
     ]
    }
   ],
   "source": [
    "# Recode the values in the \"FUEL\" column\n",
    "data[\"FUEL\"] = data[\"FUEL\"].replace({\"D\": 1, \"X\": 2, \"Z\": 3, \"N\": 4, \"E\": 5})\n",
    "# Remove the following columns from the \"data\" DataFrame\n",
    "columns_to_remove = [\"MODEL\",\"MAKE\", \"VEHICLE CLASS\", \"FUEL CONSUMPTION\", \"HWY (L/100 km)\", \"COMB (mpg)\", \"EMISSIONS\"]\n",
    "data = data.drop(columns_to_remove, axis=1)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MAKE_enc  VEHICLE CLASS_enc  TRANSMISSION_enc  YEAR  ENGINE SIZE  \\\n",
      "0  9.398477           9.180804         12.304974  2000          1.6   \n",
      "1  9.398477           9.180804          9.381036  2000          1.6   \n",
      "2  9.398477           9.791304         10.849480  2000          3.2   \n",
      "3  9.398477           9.791304         12.304974  2000          3.5   \n",
      "4  9.398477           9.908146         12.304974  2000          1.8   \n",
      "\n",
      "   CYLINDERS  FUEL  COMB (L/100 km)  ENGINE_CYLINDER_RATIO  TRANSMISSION_TYPE  \n",
      "0          4     2              8.1               0.400000                  0  \n",
      "1          4     2              7.6               0.400000                  1  \n",
      "2          6     3             10.0               0.533333                  0  \n",
      "3          6     3             11.5               0.583333                  0  \n",
      "4          4     2              8.6               0.450000                  0  \n"
     ]
    }
   ],
   "source": [
    "# Create a new feature named \"ENGINE_CYLINDER_RATIO\" as the ratio of \"ENGINE SIZE\" to \"CYLINDERS\"\n",
    "data[\"ENGINE_CYLINDER_RATIO\"] = data[\"ENGINE SIZE\"] / data[\"CYLINDERS\"]\n",
    "\n",
    "# Create a new feature named \"TRANSMISSION_TYPE\" indicating whether the car has an automatic transmission\n",
    "data[\"TRANSMISSION_TYPE\"] = data[\"TRANSMISSION\"].apply(lambda x: 0 if \"A\" in x else 1)\n",
    "\n",
    "# Remove the \"TRANSMISSION\" column from the \"data\" DataFrame\n",
    "data = data.drop(\"TRANSMISSION\", axis=1)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Split des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the target variable from the features\n",
    "X = data.drop(\"COMB (L/100 km)\", axis=1)\n",
    "y = data[\"COMB (L/100 km)\"]\n",
    "\n",
    "# Split the dataset into training and temporary sets (85% training + validation, 15% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=2)\n",
    "\n",
    "# Split the temporary set again into training and validation sets (70% / 15% of the total amount)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=(0.15 / 0.85), random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ML Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/13 16:24:37 INFO mlflow.tracking.fluent: Experiment with name 'random_forest_regressor_hyperparameter_tuning' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(\"random_forest_regressor_hyperparameter_tuning\")\n",
    "\n",
    "# Define hyperparameter search space\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [None, 10, 20, 30]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "max_features = [1.0, 'sqrt']\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_rf_model(params: Dict[str, Any], X_train: pd.DataFrame, y_train: pd.Series,\n",
    "                   X_val: pd.DataFrame, y_val: pd.Series, random_state: int = 1,\n",
    "                   log_best_model: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Train a RandomForestRegressor model with the specified hyperparameters, log the hyperparameters\n",
    "    and the mean squared error using MLflow, and return the mean squared error. Optionally log\n",
    "    the model if log_best_model is set to True.\n",
    "    \n",
    "    :param params: Dictionary containing the hyperparameters for the RandomForestRegressor model.\n",
    "    :param X_train: Training dataset features.\n",
    "    :param y_train: Training dataset target.\n",
    "    :param X_val: Validation dataset features.\n",
    "    :param y_val: Validation dataset target.\n",
    "    :param random_state: Random state for reproducibility (default: 1).\n",
    "    :param log_best_model: Log the model if set to True (default: False).\n",
    "    :return: Mean squared error on the validation dataset.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run():\n",
    "        # Create the model with the specified hyperparameters\n",
    "        rf = RandomForestRegressor(n_estimators=params['n_estimators'],\n",
    "                                   max_depth=params['max_depth'],\n",
    "                                   min_samples_split=params['min_samples_split'],\n",
    "                                   min_samples_leaf=params['min_samples_leaf'],\n",
    "                                   max_features=params['max_features'],\n",
    "                                   random_state=random_state)\n",
    "        \n",
    "        # Train the model\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions on the validation set\n",
    "        y_pred = rf.predict(X_val)\n",
    "        \n",
    "        # Calculate the mean squared error\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        # Log the hyperparameters and the mean squared error\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "       \n",
    "        \n",
    "        # Log the model with the best parameter combination if log_best_model is True\n",
    "        if log_best_model:\n",
    "            mlflow.sklearn.log_model(rf, \"random_forest_model\")\n",
    "        \n",
    "        return mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_hyperparameters(n_estimators: List[int], max_depth: List[int], min_samples_split: List[int],\n",
    "                              min_samples_leaf: List[int], max_features: List[str]) -> Tuple[float, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Find the best hyperparameters for a RandomForest model using a grid search approach.\n",
    "    \n",
    "    :param n_estimators: List of possible values for n_estimators.\n",
    "    :param max_depth: List of possible values for max_depth.\n",
    "    :param min_samples_split: List of possible values for min_samples_split.\n",
    "    :param min_samples_leaf: List of possible values for min_samples_leaf.\n",
    "    :param max_features: List of possible values for max_features.\n",
    "    :return: Tuple containing the best valid MSE and the best parameters as a dictionary.\n",
    "    \"\"\"\n",
    "    best_mse = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate through all possible combinations of hyperparameters\n",
    "    for n in n_estimators:\n",
    "        for d in max_depth:\n",
    "            for s in min_samples_split:\n",
    "                for l in min_samples_leaf:\n",
    "                    for f in max_features:\n",
    "                        params = {\n",
    "                            'n_estimators': n,\n",
    "                            'max_depth': d,\n",
    "                            'min_samples_split': s,\n",
    "                            'min_samples_leaf': l,\n",
    "                            'max_features': f\n",
    "                        }\n",
    "                        \n",
    "                        # Train the model with the current combination of hyperparameters and calculate the MSE\n",
    "                        mse = train_rf_model(params, X_train, y_train, X_val, y_val, False)\n",
    "                        \n",
    "                        # Update the best MSE and parameters if the current MSE is lower\n",
    "                        if mse < best_mse:\n",
    "                            best_mse = mse\n",
    "                            best_params = params\n",
    "\n",
    "    return best_mse, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Valid MSE: 0.3454593919560358\n",
      "Best parameters: {'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call the find_best_hyperparameters function with the defined search space\n",
    "best_mse, best_params = find_best_hyperparameters(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features)\n",
    "\n",
    "# Print the best MSE and parameters found during the hyperparameter search\n",
    "print(\"Best Valid MSE:\", best_mse)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.3123275990714805\n"
     ]
    }
   ],
   "source": [
    "# Create the model with the best hyperparameters\n",
    "test_mse = train_rf_model(best_params, X_train_val, y_train_val, X_test, y_test, log_best_model=True)\n",
    "\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DHBW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
